{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Nodes Embedding\n",
    "\n",
    "- Use Doc2Vec to embed the description, name, etc of services \n",
    "- cluster these embeddings and measure cluster performance\n",
    "\n",
    "later:\n",
    "- use [BANE](https://github.com/benedekrozemberczki/BANE) code to embed the nodes taking into account their network structure\n",
    "- compare cluster performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import typing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "# %%capture\n",
    "# tqdm().pandas()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open our datasets\n",
    "with open('./data/services_nodes.json') as sn:\n",
    "    serv_nodes = json.loads(sn.read())\n",
    "    \n",
    "with open('./data/services_edgelist.csv') as se:\n",
    "    serv_edges = csv.reader(se)\n",
    "\n",
    "with open('./data/HIN_nodes.json') as taxo:\n",
    "    taxo_nodes = json.loads(taxo.read())\n",
    "\n",
    "with open('./data/code_to_node_num.json') as cn:\n",
    "    code_trans = json.loads(cn.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following: https://towardsdatascience.com/machine-learning-text-processing-1d5a2d638958\n",
    "# other ref: https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n",
    "\n",
    "# dictionary used to store our services node content to be embeded\n",
    "serv_cont = {}\n",
    "\n",
    "# service features to be embedded as text or tags\n",
    "# maybe fix to get actual agency name instead of id\n",
    "text_feats = [\n",
    "    'name', \n",
    "    'akas', \n",
    "    'description', \n",
    "#     'codes',\n",
    "#     'eligibility'\n",
    "]\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "# returns a \n",
    "def preprocessText(text: str) -> typing.List :\n",
    "    # normalize: convert to lower, remove \n",
    "    # numbers, remove punctuation\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('','', string.digits))\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    words = []\n",
    "    # tokenize into sentences\n",
    "    text_sents = nltk.sent_tokenize(text)\n",
    "    for sent in text_sents:\n",
    "        words.extend(nltk.word_tokenize(sent))\n",
    "    \n",
    "    stop_words = set(nltk.corpus.stopwords.words())\n",
    "    # remove stopwords like 'the', 'is', 'a', etc\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    # get base form of words\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    words = [lemmer.lemmatize(w) for w in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8b3671ad754a669ae58b95f8c1adfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pre-processing Text', max=16547, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# word2vec ref: http://jalammar.github.io/illustrated-word2vec/\n",
    "\n",
    "# \"documents\" consisting of the direct and related text content from each node\n",
    "# each elem is a TaggedDocument class from gensim\n",
    "docs = []\n",
    "serv_num = len(serv_nodes)\n",
    "# for each service node\n",
    "with tqdm(total=serv_num, desc='Pre-processing Text') as pbar:\n",
    "    for node_num in serv_nodes:\n",
    "\n",
    "        node = serv_nodes[node_num]\n",
    "        words = []\n",
    "        # preprocess the text content of the node and it's taxonomy code nodes\n",
    "        for feat in text_feats:\n",
    "\n",
    "            text = node[feat]\n",
    "            if feat in ('akas', 'eligibility'):\n",
    "                text = ' '.join(text)\n",
    "\n",
    "            elif feat == 'codes':\n",
    "                for cn in node[feat]:\n",
    "                    code = taxo_nodes[str(code_trans[cn])]\n",
    "                    words.extend(preprocessText(code['name']))\n",
    "                    words.extend(preprocessText(code['description']))\n",
    "                    if 'keywords' in code:\n",
    "                        keywords = ' '.join(code['keywords'])\n",
    "                        words.extend(preprocessText(keywords))\n",
    "\n",
    "            # some nodes have empty features\n",
    "            elif text:\n",
    "                words.extend(preprocessText(text))\n",
    "            # preprocess our node raw text feats\n",
    "\n",
    "        docs.append(TaggedDocument(words=words, tags=[node_num]))\n",
    "        pbar.update(1)\n",
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like to train a model from scratch with our 16547 documents?:  Y\n"
     ]
    }
   ],
   "source": [
    "# ref for clustering embeddings: https://towardsdatascience.com/automatic-topic-clustering-using-doc2vec-e1cea88449c\n",
    "# some discussion of model parameter tuning: https://stackoverflow.com/questions/47890052/improving-gensim-doc2vec-results\n",
    "# explaining negative sampling vs hierarchical-softmax: https://stackoverflow.com/questions/46860197/doc2vec-and-word2vec-with-negative-sampling\n",
    "# more useful info on parameters: https://stackoverflow.com/questions/56323377/which-method-dm-or-dbow-works-well-for-document-similarity-using-doc2vec\n",
    "# some discussion on embedding size: https://datascience.stackexchange.com/questions/51404/word2vec-how-to-choose-the-embedding-size-parameter\n",
    "# followed this guide : https://ai.intelligentonlinetools.com/ml/text-clustering-doc2vec-word-embedding-machine-learning/\n",
    "# and gensim examples: https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\n",
    "# gensim docs: https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "# use default alpha/min-alpha learning rates. \n",
    "# use skip-gram to train word vector alongside doc vectors using dbow\n",
    "trn_prompt = ''\n",
    "while trn_prompt not in ('Y', 'N'):\n",
    "    trn_prompt = input(\"Would you like to train a model from scratch with our {} documents?: \".format(serv_num))\n",
    "    trn_prompt = trn_prompt.upper()\n",
    "train = True if trn_prompt == 'Y' else False\n",
    "\n",
    "if train:\n",
    "    model_fname = './models/doc2vec_services'\n",
    "    # model = Doc2Vec(dm=0, dbow_words=1, workers=4, negative=10, min_count=5, vector_size=150, epochs=30)\n",
    "    model = Doc2Vec(dm=1, dm_mean=1, workers=8, negative=10, min_count=5, vector_size=150, epochs=30)\n",
    "    model.build_vocab(docs)\n",
    "    model.train(docs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finished training/updating model. delete training data to reduce memory use when loaded\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model.save(model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm model was saved correctly\n",
    "model = Doc2Vec.load(model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12487cb77e8346169d59442ba35d1a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16547), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check: check if given each doc in the same training data\n",
    "# the model can return that same doc as the most similar\n",
    "def sanityCheck(model):\n",
    "    ranks = []\n",
    "    second_ranks = []\n",
    "    model_len = len(model.docvecs)\n",
    "    with tqdm(total=serv_num) as pbar:\n",
    "        for idx, doc_id in enumerate(serv_nodes):\n",
    "            inferred_vector = model.infer_vector(docs[idx].words)\n",
    "            sims = model.docvecs.most_similar([inferred_vector], topn=model_len)\n",
    "            rank = [docid for docid, sim in sims].index(doc_id)\n",
    "            ranks.append(rank)\n",
    "\n",
    "            second_ranks.append(sims[1])\n",
    "            pbar.update(1)\n",
    "        \n",
    "    import collections\n",
    "    counter = collections.Counter(ranks)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service 34003 (Street Department): «Provides street and sidewalk maintenance, storm-sewer maintenance, snow and ice control, dead animal pick-up, street-sign maintenance, mosquito control, and groundskeeping of town properties in the town of Edinburgh in Bartholomew, Johnson, and Shelby counties. Provides curbside collection of trash, leaves, and yard waste for town residents.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('41789', 0.9580173492431641) Housing Payment Assistance - Michigan City\n",
      "2-Most Similar ('41790', 0.9179282784461975) Housing Payment Assistance - Hammond\n",
      "3-Most Similar ('41788', 0.9020909070968628) Housing Payment Assistance - Gary\n",
      "\n",
      "Service 32029 (Police Department): «Provides law enforcement, crime investigation, crime prevention, emergency assistance, and other police duties for the city of New Haven in Allen County. Persons in need of emergency police assistance should call 9-1-1.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('28684', 0.9706683158874512) Building and Zoning\n",
      "2-Most Similar ('42283', 0.9347288608551025) Building And Zoning\n",
      "3-Most Similar ('37707', 0.9093565344810486) Building And Zoning\n",
      "\n",
      "Service 43033 (Family Planning): «Provides free and confidential pregnancy testing, peer counseling, material supplies, and referrals to community resources.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('32111', 0.9583746790885925) Zoning\n",
      "2-Most Similar ('39661', 0.8802120089530945) Building And Zoning\n",
      "3-Most Similar ('37055', 0.8612798452377319) Economic Development And Planning Department\n",
      "\n",
      "Service 33369 (Neighborhood Alliance For Child Safety): «Provides a home-based child abuse and neglect prevention program to Marion County families with children. Services are tailored to meet each individual family's needs and may include case management, advocacy, parent education, and referrals to community resources.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('38251', 0.9739513993263245) Head Start\n",
      "2-Most Similar ('33575', 0.9728909134864807) Head Start\n",
      "3-Most Similar ('38256', 0.9723905920982361) Head Start\n",
      "\n",
      "Service 43283 (The Compassionate Friends): «Offers a monthly support group for parents who have lost a child from birth through adulthood.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('39731', 0.9608992338180542) Financial Assistance\n",
      "2-Most Similar ('39831', 0.7203688621520996) Financial Assistance\n",
      "3-Most Similar ('30779', 0.7125636339187622) Financial Assistance\n",
      "\n",
      "Service 29299 (Planning, Zoning and Development): «Oversees housing and commercial development within the town of Pittsboro in Hendricks County. This department issues permits and conducts inspections for construction and remodeling projects, responds to reports of overgrown weeds on private property, oversees subdivision controls, and handles zoning requests, complaints, and appeals.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('36417', 0.9618768692016602) Volunteer Opportunities\n",
      "2-Most Similar ('40586', 0.7328527569770813) Volunteer Opportunity\n",
      "3-Most Similar ('39790', 0.7315201163291931) Volunteer Opportunity\n",
      "\n",
      "Service 28233 (Welcome/Bienvenido - Elkhart): «Provides support services to new immigrants from Latin American countries and promotes healthy lifestyles while adjusting to new culture. Services include preventative health education, as well as support for those facing homesickness and depression.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('34185', 0.9639267325401306) Ican Food Pantry\n",
      "2-Most Similar ('43827', 0.9635158777236938) Dare To Care\n",
      "3-Most Similar ('33895', 0.9634205102920532) Food Pantry\n",
      "\n",
      "Service 32304 (Police Department): «Provides law enforcement, crime investigation, crime prevention, emergency assistance, and other police duties for the city of Decatur in Adams County. Persons in need of emergency police assistance should call 9-1-1.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('33491', 0.9600345492362976) Recycling Drop-Off Sites\n",
      "2-Most Similar ('30614', 0.8648854494094849) Recycling\n",
      "3-Most Similar ('30615', 0.8595902323722839) Recycling\n",
      "\n",
      "Service 41184 (Car Seat Inspection): «Provides evaluation of child’s current traveling set-up and instructs parent or caregiver on proper use and installation of child restraints.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('40789', 0.9622358679771423) Financial Assistance\n",
      "2-Most Similar ('34289', 0.5444459319114685) Food Pantry\n",
      "3-Most Similar ('30444', 0.5148870944976807) Financial Assistance\n",
      "\n",
      "Service 35038 (Donations): «Accepts donations of furniture and working appliances. Pick-up is available within Monroe County.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow+w,d150,n10,w5,mc5,s0.001,t4):\n",
      "\n",
      "1-Most Similar ('40290', 0.969205379486084) Meal Sites, Seniors\n",
      "2-Most Similar ('40280', 0.9691988825798035) Meal Sites, Seniors\n",
      "3-Most Similar ('40287', 0.9680439829826355) Meal Sites, Seniors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test random example \n",
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    doc_id = random.choice(list(serv_nodes.keys()))\n",
    "    doc_idx = random.randint(0,serv_num)\n",
    "    inferred_vector = model.infer_vector(docs[doc_idx].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=100)\n",
    "    print('Service {} ({}): «{}»\\n'.format(doc_id, serv_nodes[doc_id]['name'], serv_nodes[doc_id]['description']))\n",
    "    print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "    for i in range(0,3):\n",
    "        label = \"{}-Most Similar\".format(i+1)\n",
    "        print(\"{} {} {}\".format(label, sims[i], serv_nodes[sims[i][0]]['name']))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ba5ffef71fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Police'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Law'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.similarity('Police', 'Law')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
